{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cdd513b",
   "metadata": {},
   "source": [
    "# ETL Process: Shopping Behavior Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc721cfa",
   "metadata": {},
   "source": [
    "This notebook demonstrates a complete ETL (Extract, Transform, Load) process on two consumer shopping behavior datasets. The goal is to clean, transform, and merge the datasets for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bec00e",
   "metadata": {},
   "source": [
    "## Step 1: Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5902e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "behavior_df = pd.read_csv('shopping_behavior_updated.csv')\n",
    "trends_df = pd.read_csv('shopping_trends.csv')\n",
    "\n",
    "# Display the first few rows of both datasets\n",
    "display(behavior_df.head())\n",
    "display(trends_df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274851c8",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize column names for consistency\n",
    "behavior_df.columns = behavior_df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "trends_df.columns = trends_df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Check for missing values\n",
    "print(behavior_df.isnull().sum())\n",
    "print(trends_df.isnull().sum())\n",
    "\n",
    "# Fill missing values with appropriate defaults\n",
    "behavior_df.fillna({'review_rating': behavior_df['review_rating'].mean()}, inplace=True)\n",
    "trends_df.fillna({'review_rating': trends_df['review_rating'].mean()}, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974f93a",
   "metadata": {},
   "source": [
    "## Step 3: Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the two datasets on 'customer_id'\n",
    "merged_df = pd.merge(behavior_df, trends_df, on='customer_id', suffixes=('_behavior', '_trends'))\n",
    "\n",
    "# Drop duplicate columns\n",
    "merged_df.drop(columns=['age_trends', 'gender_trends'], inplace=True)\n",
    "\n",
    "# Display the merged dataset\n",
    "display(merged_df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e461107",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999872e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new feature 'total_purchase_amount' combining purchase amounts from both datasets\n",
    "merged_df['total_purchase_amount'] = merged_df['purchase_amount_(usd)_behavior'] + merged_df['purchase_amount_(usd)_trends']\n",
    "\n",
    "# Encode categorical variables for analysis\n",
    "merged_df['is_subscribed'] = merged_df['subscription_status_behavior'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Display the updated dataset\n",
    "display(merged_df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad06b89",
   "metadata": {},
   "source": [
    "## Step 5: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the transformed dataset to a new CSV file\n",
    "output_file_path = 'cleaned_shopping_data.csv'\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Transformed dataset saved to {output_file_path}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
